---
title: "Initiation à la Textométrie avec R"
author: "Florian Cafiero"
date: "2024-11-25"
output: html_document
---

# Introduction

La textométrie est une discipline qui combine des approches statistiques et informatiques pour analyser des corpus de textes. Elle offre aux chercheurs en sciences humaines des outils puissants pour explorer des volumes importants de données textuelles, permettant ainsi de révéler des structures, des thèmes et des tendances qui ne sont pas immédiatement apparents à la lecture traditionnelle.



1. **Préparation et exploration des données**

2. **Analyse lexicale**


3. **Analyse thématique**

4. **Analyse comparative**

5. **Visualisation et interprétation des résultats**


- **Packages R nécessaires** :
  - `tidyverse`
  - `quanteda`
  - `topicmodels`
  - `ggplot2`
  - `igraph` (pour les graphes de co-occurrences)

Assurez-vous d'avoir ces packages installés avant de commencer.

## Résultats attendus

À l'issue de ce TP, vous serez en mesure de :

- Importer et préparer un corpus textuel pour l'analyse en R.
- Réaliser des analyses lexicales et thématiques de base.
- Interpréter les résultats de ces analyses dans le contexte des sciences humaines.
- Visualiser les données textuelles de manière informative.


# Partie 1 : Préparation et Exploration des Données

## Objectifs

Dans cette première partie, nous allons apprendre à :

- Importer un corpus de textes dans R.
- Nettoyer et préparer les données textuelles pour l'analyse.
- Explorer le corpus à l'aide de statistiques descriptives de base.

---

## 1.1 Chargement et découverte du corpus

### Étape 1 : Installation et chargement des packages

Avant de commencer, assurez-vous que les packages nécessaires sont installés et chargés dans votre environnement R.

```r
# Installer les packages si nécessaire
install.packages(c("tidyverse", "quanteda"))

# Charger les packages
library(tidyverse)
library(quanteda)
```


## 1.2 Nettoyage de corpus

Nous allons nettoyer les textes pour faciliter les analyses. Les étapes incluent la suppression des majuscules, des ponctuations, et des espaces superflus.

```r
# Nettoyage des textes
corpus_df <- corpus_df %>%
  mutate(
    text_clean = text %>%
      str_to_lower() %>%
      str_replace_all("[[:punct:]]", " ") %>%
      str_squish()
  )

# Aperçu des textes nettoyés
head(corpus_df$text_clean)
```

```r
# Création d'un objet corpus
corpus <- corpus(corpus_df, text_field = "text_clean")

# Résumé du corpus
summary(corpus)

# Statistiques descriptives du corpus
corpus_summary <- textstat_summary(corpus)
corpus_summary


# Longueur des documents (en nombre de mots)
doc_lengths <- ntoken(corpus)

# Visualisation avec ggplot2
ggplot(data = tibble(doc = names(doc_lengths), length = doc_lengths)) +
  geom_histogram(aes(x = length), bins = 20, fill = "blue", alpha = 0.7) +
  labs(
    title = "Distribution des longueurs de documents",
    x = "Nombre de mots",
    y = "Nombre de documents"
  ) +
  theme_minimal()

```



